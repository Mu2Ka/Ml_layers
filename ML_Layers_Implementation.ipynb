{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.137074Z",
     "start_time": "2025-08-28T12:56:23.131142Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from typing import Optional, List\n",
    "\n",
    "# Установим seed для воспроизводимости\n",
    "np.random.seed(42)\n"
   ],
   "outputs": [],
   "execution_count": 402
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.170100Z",
     "start_time": "2025-08-28T12:56:23.164785Z"
    }
   },
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    Базовый класс для всех слоев нейронной сети\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Переключение в режим обучения\n",
    "        \"\"\"\n",
    "        self.training = True\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        Переключение в режим инференса\n",
    "        \"\"\"\n",
    "        self.training = False\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n"
   ],
   "outputs": [],
   "execution_count": 403
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.197294Z",
     "start_time": "2025-08-28T12:56:23.193271Z"
    }
   },
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение для ReLU\n",
    "        \n",
    "        Args:\n",
    "\n",
    "        \n",
    "        Returns:\n",
    "            выходной тензор той же формы\n",
    "        \"\"\"\n",
    "        # TODO: Сохраните входные данные для backward pass\n",
    "        self.input = x\n",
    "\n",
    "        # TODO: Реализуйте ReLU функцию\n",
    "        output = np.maximum(0, x)\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение для ReLU\n",
    "        \n",
    "        Args:\n",
    "            grad_output: градиент от следующего слоя\n",
    "        \n",
    "        Returns:\n",
    "            градиент для предыдущего слоя\n",
    "        \"\"\"\n",
    "        # TODO: Реализуйте градиент ReLU\n",
    "        self.mask = self.input > 0\n",
    "        grad_input = grad_output * self.mask\n",
    "\n",
    "        return grad_input\n"
   ],
   "outputs": [],
   "execution_count": 404
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.225766Z",
     "start_time": "2025-08-28T12:56:23.219807Z"
    }
   },
   "source": [
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение для Sigmoid\n",
    "        \n",
    "        Args:\n",
    "            x: входной тензор\n",
    "        \n",
    "        Returns:\n",
    "            выходной тензор той же формы, значения в диапазоне (0, 1)\n",
    "        \"\"\"\n",
    "        # TODO: Реализуйте sigmoid функцию\n",
    "        self.output = 1 / (1 + np.exp(-x))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение для Sigmoid\n",
    "        \n",
    "        Args:\n",
    "            grad_output: градиент от следующего слоя\n",
    "        \n",
    "        Returns:\n",
    "            градиент для предыдущего слоя\n",
    "        \"\"\"\n",
    "        # TODO: Реализуйте градиент sigmoid\n",
    "        derivative_sigm = self.output * (1 - self.output)\n",
    "        grad_input = derivative_sigm * grad_output\n",
    "        return grad_input\n"
   ],
   "outputs": [],
   "execution_count": 405
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.252861Z",
     "start_time": "2025-08-28T12:56:23.248858Z"
    }
   },
   "source": [
    "class Tanh(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение для Tanh\n",
    "        \n",
    "        Args:\n",
    "            x: входной тензор\n",
    "        \n",
    "        Returns:\n",
    "            выходной тензор той же формы, значения в диапазоне (-1, 1)\n",
    "        \"\"\"\n",
    "        # TODO: Реализуйте tanh функцию\n",
    "        self.output = np.tanh(x)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение для Tanh\n",
    "        \n",
    "        Args:\n",
    "            grad_output: градиент от следующего слоя\n",
    "        \n",
    "        Returns:\n",
    "            градиент для предыдущего слоя\n",
    "        \"\"\"\n",
    "        # TODO: Реализуйте градиент tanh\n",
    "\n",
    "        derivative_tanh = 1 - self.output ** 2\n",
    "        grad_input = grad_output * derivative_tanh\n",
    "\n",
    "        return grad_input\n"
   ],
   "outputs": [],
   "execution_count": 406
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.280805Z",
     "start_time": "2025-08-28T12:56:23.273725Z"
    }
   },
   "source": [
    "class Linear(Layer):\n",
    "    def __init__(self, input_size, output_size, bias=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.use_bias = bias\n",
    "\n",
    "        # TODO: Инициализируйте веса\n",
    "        limit = np.sqrt(6 / (input_size + output_size))\n",
    "        self.weight = np.random.uniform(-limit, limit, (input_size, output_size))\n",
    "\n",
    "        # TODO: Инициализируйте bias (если используется)\n",
    "        if self.use_bias:\n",
    "            self.bias = np.zeros(output_size)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        # Переменные для сохранения входных данных и градиентов\n",
    "        self.input = None\n",
    "        self.grad_weight = None\n",
    "        self.grad_bias = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение для линейного слоя\n",
    "        \n",
    "        Args:\n",
    "            x: входной тензор формы (batch_size, input_size)\n",
    "        \n",
    "        Returns:\n",
    "            выходной тензор формы (batch_size, output_size)\n",
    "        \"\"\"\n",
    "        # TODO: Сохраните входные данные для backward pass\n",
    "        self.input = x\n",
    "\n",
    "        # TODO: Реализуйте линейное преобразование\n",
    "        output = self.input @ self.weight\n",
    "\n",
    "        if self.use_bias:\n",
    "            output = output + self.bias\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение для линейного слоя\n",
    "        \n",
    "        Args:\n",
    "            grad_output: градиент от следующего слоя формы (batch_size, output_size)\n",
    "        \n",
    "        Returns:\n",
    "            градиент для предыдущего слоя формы (batch_size, input_size)\n",
    "        \"\"\"\n",
    "        # TODO: Вычислите градиент по входу\n",
    "        grad_input = grad_output @ self.weight.T\n",
    "\n",
    "        # TODO: Вычислите градиент по весам\n",
    "        self.grad_weight = self.input.T @ grad_output\n",
    "\n",
    "        # TODO: Вычислите градиент по bias\n",
    "        if self.use_bias:\n",
    "            self.grad_bias = np.sum(grad_output, axis=0)\n",
    "        return grad_input\n",
    "\n",
    "    def update_weights(self, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Обновление весов с помощью градиентного спуска\n",
    "        \"\"\"\n",
    "        if self.grad_weight is not None:\n",
    "            self.weight -= learning_rate * self.grad_weight\n",
    "\n",
    "        if self.use_bias and self.grad_bias is not None:\n",
    "            self.bias -= learning_rate * self.grad_bias\n"
   ],
   "outputs": [],
   "execution_count": 407
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.307945Z",
     "start_time": "2025-08-28T12:56:23.301944Z"
    }
   },
   "source": [
    "class Sequential(Layer):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = list(layers)\n",
    "        self.layer_outputs = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        \"\"\"\n",
    "        Добавление слоя в последовательность\n",
    "        \"\"\"\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение через все слои\n",
    "        \n",
    "        Args:\n",
    "            x: входной тензор\n",
    "        \n",
    "        Returns:\n",
    "            выходной тензор после прохождения всех слоев\n",
    "        \"\"\"\n",
    "        # TODO: Очистите список промежуточных выходов\n",
    "        self.layer_outputs = []\n",
    "\n",
    "        # TODO: Последовательно примените все слои\n",
    "        output = x\n",
    "        for layer in self.layers:\n",
    "            # TODO: Применить слой и сохранить результат\n",
    "            output = layer.forward(output)  # Применяем слой\n",
    "            self.layer_outputs.append(output)  # Сохраняем выход слоя\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение через все слои в обратном порядке\n",
    "        \n",
    "        Args:\n",
    "            grad_output: градиент от следующего слоя\n",
    "        \n",
    "        Returns:\n",
    "            градиент для предыдущего слоя\n",
    "        \"\"\"\n",
    "        # TODO: Примените backward для всех слоев в обратном порядке\n",
    "        grad = grad_output\n",
    "        for layer in reversed(self.layers):\n",
    "            # TODO: Примените backward для текущего слоя\n",
    "            grad = layer.backward(grad)  # Применяем слой\n",
    "        return grad\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Переключение всех слоев в режим обучения\n",
    "        \"\"\"\n",
    "        super().train()\n",
    "        for layer in self.layers:\n",
    "            layer.train()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"\n",
    "        Переключение всех слоев в режим инференса\n",
    "        \"\"\"\n",
    "        super().eval()\n",
    "        for layer in self.layers:\n",
    "            layer.eval()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.layers)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.layers[idx]\n"
   ],
   "outputs": [],
   "execution_count": 408
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.344039Z",
     "start_time": "2025-08-28T12:56:23.337573Z"
    }
   },
   "source": [
    "class Dropout(Layer):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение для Dropout\n",
    "        \n",
    "        Args:\n",
    "            x: входной тензор\n",
    "        \n",
    "        Returns:\n",
    "            выходной тензор с примененным dropout (в режиме обучения)\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            # TODO: Создайте бинарную маску для dropout\n",
    "            self.mask = np.random.binomial(1, 1 - self.dropout_rate, size=x.shape)\n",
    "\n",
    "            # TODO: Примените маску и масштабирование\n",
    "            output = (x * self.mask) / (1 - self.dropout_rate)\n",
    "        else:\n",
    "            # TODO: В режиме инференса\n",
    "            output = x\n",
    "            self.mask = None\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        Обратное распространение для Dropout\n",
    "        \n",
    "        Args:\n",
    "            grad_output: градиент от следующего слоя\n",
    "        \n",
    "        Returns:\n",
    "            градиент для предыдущего слоя\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            # TODO: Примените ту же маску к градиенту\n",
    "            grad_input = grad_output * self.mask\n",
    "        else:\n",
    "            grad_input = grad_output\n",
    "        return grad_input\n"
   ],
   "outputs": [],
   "execution_count": 409
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.373109Z",
     "start_time": "2025-08-28T12:56:23.365132Z"
    }
   },
   "source": [
    "class BatchNorm(Layer):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "\n",
    "        # TODO: Инициализируйте обучаемые параметры gamma и beta\n",
    "        self.gamma = np.ones(num_features)\n",
    "        self.beta = np.zeros(num_features)\n",
    "        # TODO: Инициализируйте накопленную статистику\n",
    "        self.running_mean = np.zeros(num_features)\n",
    "        self.running_var = np.ones(num_features)\n",
    "\n",
    "        # Переменные для backward pass\n",
    "        self.batch_mean = None\n",
    "        self.batch_var = None\n",
    "        self.normalized = None\n",
    "        self.input = None\n",
    "        self.grad_gamma = None\n",
    "        self.grad_beta = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямое распространение для Batch Normalization\n",
    "        \n",
    "        Args:\n",
    "            x: входной тензор формы (batch_size, num_features)\n",
    "        \n",
    "        Returns:\n",
    "            нормализованный выходной тензор той же формы\n",
    "        \"\"\"\n",
    "        self.input = x\n",
    "\n",
    "        if self.training:\n",
    "            # TODO: Вычислите статистику текущего batch\n",
    "            self.batch_mean = np.mean(x, axis=0)\n",
    "            self.batch_var = np.var(x, axis=0)\n",
    "\n",
    "            # TODO: Обновите накопленную статистику\n",
    "            self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * self.batch_mean\n",
    "            self.running_var = (1 - self.momentum) * self.running_var + self.momentum * self.batch_var\n",
    "\n",
    "            mean = self.batch_mean\n",
    "            var = self.batch_var\n",
    "        else:\n",
    "            # TODO: Используйте накопленную статистику\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        # TODO: Нормализация\n",
    "        self.normalized = (x - mean) / np.sqrt(var + self.eps)\n",
    "\n",
    "        # TODO: Масштабирование и сдвиг\n",
    "        output = self.gamma * self.normalized + self.beta\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        m = grad_output.shape[0]\n",
    "\n",
    "        # --- градиенты по γ и β ---\n",
    "        self.grad_gamma = np.sum(grad_output * self.normalized, axis=0)\n",
    "        self.grad_beta = np.sum(grad_output, axis=0)\n",
    "\n",
    "        # dL/dy * γ\n",
    "        grad_y = grad_output * self.gamma\n",
    "\n",
    "        # выбираем статистику (как в forward)\n",
    "        if self.training:\n",
    "            mean = self.batch_mean\n",
    "            var = self.batch_var\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            var = self.running_var\n",
    "\n",
    "        # dL/d(var)\n",
    "        dvar = np.sum(\n",
    "            grad_y * (self.input - mean) * -0.5 * (var + self.eps) ** (-3 / 2),\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "        # dL/d(mean)\n",
    "        dmean = np.sum(-grad_y / np.sqrt(var + self.eps), axis=0) + \\\n",
    "                dvar * np.mean(-2.0 * (self.input - mean), axis=0)\n",
    "\n",
    "        # dL/dx\n",
    "        grad_input = grad_y / np.sqrt(var + self.eps) + \\\n",
    "                     dvar * 2 * (self.input - mean) / m + \\\n",
    "                     dmean / m\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "    def update_weights(self, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        Обновление параметров\n",
    "        \"\"\"\n",
    "        if self.grad_gamma is not None:\n",
    "            self.gamma -= learning_rate * self.grad_gamma\n",
    "\n",
    "        if self.grad_beta is not None:\n",
    "            self.beta -= learning_rate * self.grad_beta\n"
   ],
   "outputs": [],
   "execution_count": 410
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.399149Z",
     "start_time": "2025-08-28T12:56:23.392121Z"
    }
   },
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Устойчивая реализация softmax\n",
    "    \"\"\"\n",
    "    # TODO: Реализуйте softmax функцию\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    \"\"\"\n",
    "    Преобразование меток в one-hot кодировку\n",
    "    \"\"\"\n",
    "    # TODO: Создайте one-hot кодировку\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        self.predictions = None\n",
    "        self.targets = None\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Вычисление Cross-Entropy Loss\n",
    "\n",
    "        Args:\n",
    "            predictions: предсказания модели (batch_size, num_classes)\n",
    "            targets: истинные метки класса (batch_size,)\n",
    "\n",
    "        Returns:\n",
    "            значение функции потерь\n",
    "        \"\"\"\n",
    "        self.predictions = predictions\n",
    "        self.targets = targets\n",
    "\n",
    "        # TODO: Примените softmax к предсказаниям\n",
    "        self.softmax_pred = softmax(self.predictions)\n",
    "\n",
    "        # TODO: Вычислите cross-entropy loss\n",
    "        loss = -np.mean(np.log(self.softmax_pred + 1e-8))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Вычисление градиента Cross-Entropy Loss\n",
    "\n",
    "        Returns:\n",
    "            градиент по предсказаниям\n",
    "        \"\"\"\n",
    "        # TODO: Вычислите градиент\n",
    "        # Превращаем метки в one-hot (например, [2] → [0,0,1])\n",
    "        targets_one_hot = np.eye(self.softmax_pred.shape[1])[self.targets]\n",
    "\n",
    "        batch_size = self.predictions.shape[0]\n",
    "        grad = (self.softmax_pred - targets_one_hot) / batch_size\n",
    "        return grad\n",
    "\n",
    "\n",
    "class MSELoss:\n",
    "    def __init__(self):\n",
    "        self.predictions = None\n",
    "        self.targets = None\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Вычисление Mean Squared Error\n",
    "\n",
    "        Args:\n",
    "            predictions: предсказания модели\n",
    "            targets: истинные значения\n",
    "\n",
    "        Returns:\n",
    "            значение функции потерь\n",
    "        \"\"\"\n",
    "        self.predictions = predictions\n",
    "        self.targets = targets\n",
    "        batch_size = targets.shape[0]\n",
    "        # TODO: Вычислите MSE\n",
    "        loss = np.mean((predictions - targets) ** 2)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, predictions, targets):\n",
    "        batch_size = self.predictions.shape[0]\n",
    "        grad = 2 * (self.predictions - self.targets) / batch_size\n",
    "        return grad"
   ],
   "outputs": [],
   "execution_count": 411
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.428694Z",
     "start_time": "2025-08-28T12:56:23.422286Z"
    }
   },
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # TODO: Создайте архитектуру нейронной сети\n",
    "        self.model = Sequential(\n",
    "            Linear(input_size, hidden_size),\n",
    "            # BatchNorm(hidden_size),\n",
    "            Tanh(),\n",
    "            # Dropout(0.8),\n",
    "            Linear(hidden_size, output_size)\n",
    "        )\n",
    "        self.loss = MSELoss()\n",
    "        self.learning_rate = 0.01\n",
    "        self.epochs = 200\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return self.model.backward(grad_output)\n",
    "\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "    def get_trainable_layers(self):\n",
    "        \"\"\"\n",
    "        Получение всех слоев с обучаемыми параметрами\n",
    "        \"\"\"\n",
    "        trainable_layers = []\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'update_weights'):\n",
    "                trainable_layers.append(layer)\n",
    "        return trainable_layers\n",
    "\n",
    "\n",
    "    # MSE\n",
    "    def get_loss(self, y_pred, y_true):\n",
    "        return self.loss.forward(y_pred, y_true)\n",
    "\n",
    "\n",
    "    def get_gradient(self, y_pred, y_true):\n",
    "        return self.loss.backward(y_pred, y_true)\n",
    "\n",
    "\n",
    "    def train(self, x_train, y_train, X_val=None, y_val=None):\n",
    "        self.model.train()\n",
    "        train_loses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = self.forward(x_train)\n",
    "            loss = self.get_loss(y_pred, y_train)\n",
    "            grad = self.get_gradient(y_pred, y_train)\n",
    "            train_loses.append(loss)\n",
    "            self.backward(grad)\n",
    "            for layer in self.get_trainable_layers():\n",
    "                layer.update_weights(self.learning_rate)\n",
    "            if X_val is not None:\n",
    "                self.eval()\n",
    "                val_pred = self.forward(X_val)\n",
    "                val_loss = self.get_loss(val_pred, y_val)\n",
    "                val_losses.append(val_loss)\n",
    "            log = f\"Epoch {epoch + 1}/{self.epochs}, Train Loss: {loss:.4f}\"\n",
    "            if X_val is not None:\n",
    "                log += f\", Val Loss: {val_loss:.4f}\"\n",
    "            print(log)\n",
    "        return train_loses, val_losses"
   ],
   "outputs": [],
   "execution_count": 412
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# тест"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:56:23.474359Z",
     "start_time": "2025-08-28T12:56:23.449755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_samples = 200\n",
    "n_features = 2\n",
    "n_val = 50\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Настоящая функция: y = x1*2 - x2*3 + шум\n",
    "true_w = np.array([2.0, -3.0])\n",
    "y = X @ true_w + np.random.randn(n_samples) * 0.5  # добавляем шум\n",
    "y = y.reshape(-1, 1)  # делаем столбец (n_samples, 1)\n",
    "\n",
    "# Разбиваем на train/val\n",
    "X_train, y_train = X[:-n_val], y[:-n_val]\n",
    "X_val, y_val = X[-n_val:], y[-n_val:]\n",
    "first_neural = NeuralNetwork(2, 8, 1)\n",
    "train_loses, val_loses = first_neural.train(X_train, y_train, X_val=X_val, y_val=y_val)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 12.9504, Val Loss: 9.7478\n",
      "Epoch 2/200, Train Loss: 12.0186, Val Loss: 9.0470\n",
      "Epoch 3/200, Train Loss: 11.1600, Val Loss: 8.3966\n",
      "Epoch 4/200, Train Loss: 10.3668, Val Loss: 7.7918\n",
      "Epoch 5/200, Train Loss: 9.6329, Val Loss: 7.2291\n",
      "Epoch 6/200, Train Loss: 8.9532, Val Loss: 6.7055\n",
      "Epoch 7/200, Train Loss: 8.3236, Val Loss: 6.2185\n",
      "Epoch 8/200, Train Loss: 7.7405, Val Loss: 5.7657\n",
      "Epoch 9/200, Train Loss: 7.2005, Val Loss: 5.3451\n",
      "Epoch 10/200, Train Loss: 6.7006, Val Loss: 4.9545\n",
      "Epoch 11/200, Train Loss: 6.2378, Val Loss: 4.5921\n",
      "Epoch 12/200, Train Loss: 5.8095, Val Loss: 4.2560\n",
      "Epoch 13/200, Train Loss: 5.4131, Val Loss: 3.9446\n",
      "Epoch 14/200, Train Loss: 5.0464, Val Loss: 3.6562\n",
      "Epoch 15/200, Train Loss: 4.7072, Val Loss: 3.3893\n",
      "Epoch 16/200, Train Loss: 4.3936, Val Loss: 3.1425\n",
      "Epoch 17/200, Train Loss: 4.1038, Val Loss: 2.9146\n",
      "Epoch 18/200, Train Loss: 3.8362, Val Loss: 2.7043\n",
      "Epoch 19/200, Train Loss: 3.5893, Val Loss: 2.5104\n",
      "Epoch 20/200, Train Loss: 3.3616, Val Loss: 2.3318\n",
      "Epoch 21/200, Train Loss: 3.1518, Val Loss: 2.1677\n",
      "Epoch 22/200, Train Loss: 2.9588, Val Loss: 2.0168\n",
      "Epoch 23/200, Train Loss: 2.7813, Val Loss: 1.8785\n",
      "Epoch 24/200, Train Loss: 2.6183, Val Loss: 1.7517\n",
      "Epoch 25/200, Train Loss: 2.4687, Val Loss: 1.6356\n",
      "Epoch 26/200, Train Loss: 2.3315, Val Loss: 1.5296\n",
      "Epoch 27/200, Train Loss: 2.2058, Val Loss: 1.4327\n",
      "Epoch 28/200, Train Loss: 2.0908, Val Loss: 1.3444\n",
      "Epoch 29/200, Train Loss: 1.9857, Val Loss: 1.2640\n",
      "Epoch 30/200, Train Loss: 1.8896, Val Loss: 1.1909\n",
      "Epoch 31/200, Train Loss: 1.8019, Val Loss: 1.1244\n",
      "Epoch 32/200, Train Loss: 1.7219, Val Loss: 1.0641\n",
      "Epoch 33/200, Train Loss: 1.6489, Val Loss: 1.0094\n",
      "Epoch 34/200, Train Loss: 1.5824, Val Loss: 0.9598\n",
      "Epoch 35/200, Train Loss: 1.5219, Val Loss: 0.9150\n",
      "Epoch 36/200, Train Loss: 1.4667, Val Loss: 0.8744\n",
      "Epoch 37/200, Train Loss: 1.4165, Val Loss: 0.8378\n",
      "Epoch 38/200, Train Loss: 1.3709, Val Loss: 0.8048\n",
      "Epoch 39/200, Train Loss: 1.3294, Val Loss: 0.7750\n",
      "Epoch 40/200, Train Loss: 1.2916, Val Loss: 0.7481\n",
      "Epoch 41/200, Train Loss: 1.2572, Val Loss: 0.7240\n",
      "Epoch 42/200, Train Loss: 1.2259, Val Loss: 0.7022\n",
      "Epoch 43/200, Train Loss: 1.1975, Val Loss: 0.6826\n",
      "Epoch 44/200, Train Loss: 1.1716, Val Loss: 0.6651\n",
      "Epoch 45/200, Train Loss: 1.1480, Val Loss: 0.6492\n",
      "Epoch 46/200, Train Loss: 1.1266, Val Loss: 0.6350\n",
      "Epoch 47/200, Train Loss: 1.1070, Val Loss: 0.6223\n",
      "Epoch 48/200, Train Loss: 1.0891, Val Loss: 0.6108\n",
      "Epoch 49/200, Train Loss: 1.0728, Val Loss: 0.6005\n",
      "Epoch 50/200, Train Loss: 1.0579, Val Loss: 0.5912\n",
      "Epoch 51/200, Train Loss: 1.0443, Val Loss: 0.5829\n",
      "Epoch 52/200, Train Loss: 1.0318, Val Loss: 0.5754\n",
      "Epoch 53/200, Train Loss: 1.0203, Val Loss: 0.5686\n",
      "Epoch 54/200, Train Loss: 1.0097, Val Loss: 0.5626\n",
      "Epoch 55/200, Train Loss: 1.0000, Val Loss: 0.5570\n",
      "Epoch 56/200, Train Loss: 0.9911, Val Loss: 0.5521\n",
      "Epoch 57/200, Train Loss: 0.9828, Val Loss: 0.5476\n",
      "Epoch 58/200, Train Loss: 0.9751, Val Loss: 0.5434\n",
      "Epoch 59/200, Train Loss: 0.9680, Val Loss: 0.5397\n",
      "Epoch 60/200, Train Loss: 0.9614, Val Loss: 0.5363\n",
      "Epoch 61/200, Train Loss: 0.9552, Val Loss: 0.5331\n",
      "Epoch 62/200, Train Loss: 0.9494, Val Loss: 0.5303\n",
      "Epoch 63/200, Train Loss: 0.9440, Val Loss: 0.5276\n",
      "Epoch 64/200, Train Loss: 0.9389, Val Loss: 0.5251\n",
      "Epoch 65/200, Train Loss: 0.9340, Val Loss: 0.5228\n",
      "Epoch 66/200, Train Loss: 0.9295, Val Loss: 0.5206\n",
      "Epoch 67/200, Train Loss: 0.9252, Val Loss: 0.5186\n",
      "Epoch 68/200, Train Loss: 0.9211, Val Loss: 0.5167\n",
      "Epoch 69/200, Train Loss: 0.9171, Val Loss: 0.5148\n",
      "Epoch 70/200, Train Loss: 0.9134, Val Loss: 0.5131\n",
      "Epoch 71/200, Train Loss: 0.9098, Val Loss: 0.5114\n",
      "Epoch 72/200, Train Loss: 0.9063, Val Loss: 0.5098\n",
      "Epoch 73/200, Train Loss: 0.9030, Val Loss: 0.5082\n",
      "Epoch 74/200, Train Loss: 0.8998, Val Loss: 0.5067\n",
      "Epoch 75/200, Train Loss: 0.8967, Val Loss: 0.5052\n",
      "Epoch 76/200, Train Loss: 0.8936, Val Loss: 0.5037\n",
      "Epoch 77/200, Train Loss: 0.8907, Val Loss: 0.5023\n",
      "Epoch 78/200, Train Loss: 0.8878, Val Loss: 0.5009\n",
      "Epoch 79/200, Train Loss: 0.8850, Val Loss: 0.4995\n",
      "Epoch 80/200, Train Loss: 0.8823, Val Loss: 0.4981\n",
      "Epoch 81/200, Train Loss: 0.8796, Val Loss: 0.4967\n",
      "Epoch 82/200, Train Loss: 0.8770, Val Loss: 0.4953\n",
      "Epoch 83/200, Train Loss: 0.8744, Val Loss: 0.4940\n",
      "Epoch 84/200, Train Loss: 0.8719, Val Loss: 0.4926\n",
      "Epoch 85/200, Train Loss: 0.8694, Val Loss: 0.4913\n",
      "Epoch 86/200, Train Loss: 0.8669, Val Loss: 0.4899\n",
      "Epoch 87/200, Train Loss: 0.8645, Val Loss: 0.4886\n",
      "Epoch 88/200, Train Loss: 0.8621, Val Loss: 0.4872\n",
      "Epoch 89/200, Train Loss: 0.8597, Val Loss: 0.4859\n",
      "Epoch 90/200, Train Loss: 0.8574, Val Loss: 0.4845\n",
      "Epoch 91/200, Train Loss: 0.8550, Val Loss: 0.4832\n",
      "Epoch 92/200, Train Loss: 0.8527, Val Loss: 0.4819\n",
      "Epoch 93/200, Train Loss: 0.8505, Val Loss: 0.4805\n",
      "Epoch 94/200, Train Loss: 0.8482, Val Loss: 0.4792\n",
      "Epoch 95/200, Train Loss: 0.8460, Val Loss: 0.4778\n",
      "Epoch 96/200, Train Loss: 0.8438, Val Loss: 0.4765\n",
      "Epoch 97/200, Train Loss: 0.8416, Val Loss: 0.4751\n",
      "Epoch 98/200, Train Loss: 0.8394, Val Loss: 0.4738\n",
      "Epoch 99/200, Train Loss: 0.8373, Val Loss: 0.4724\n",
      "Epoch 100/200, Train Loss: 0.8351, Val Loss: 0.4711\n",
      "Epoch 101/200, Train Loss: 0.8330, Val Loss: 0.4697\n",
      "Epoch 102/200, Train Loss: 0.8309, Val Loss: 0.4684\n",
      "Epoch 103/200, Train Loss: 0.8288, Val Loss: 0.4671\n",
      "Epoch 104/200, Train Loss: 0.8267, Val Loss: 0.4657\n",
      "Epoch 105/200, Train Loss: 0.8246, Val Loss: 0.4644\n",
      "Epoch 106/200, Train Loss: 0.8226, Val Loss: 0.4630\n",
      "Epoch 107/200, Train Loss: 0.8205, Val Loss: 0.4617\n",
      "Epoch 108/200, Train Loss: 0.8185, Val Loss: 0.4604\n",
      "Epoch 109/200, Train Loss: 0.8165, Val Loss: 0.4590\n",
      "Epoch 110/200, Train Loss: 0.8145, Val Loss: 0.4577\n",
      "Epoch 111/200, Train Loss: 0.8125, Val Loss: 0.4564\n",
      "Epoch 112/200, Train Loss: 0.8105, Val Loss: 0.4551\n",
      "Epoch 113/200, Train Loss: 0.8085, Val Loss: 0.4538\n",
      "Epoch 114/200, Train Loss: 0.8066, Val Loss: 0.4525\n",
      "Epoch 115/200, Train Loss: 0.8046, Val Loss: 0.4512\n",
      "Epoch 116/200, Train Loss: 0.8027, Val Loss: 0.4499\n",
      "Epoch 117/200, Train Loss: 0.8008, Val Loss: 0.4486\n",
      "Epoch 118/200, Train Loss: 0.7989, Val Loss: 0.4473\n",
      "Epoch 119/200, Train Loss: 0.7970, Val Loss: 0.4460\n",
      "Epoch 120/200, Train Loss: 0.7951, Val Loss: 0.4447\n",
      "Epoch 121/200, Train Loss: 0.7932, Val Loss: 0.4434\n",
      "Epoch 122/200, Train Loss: 0.7914, Val Loss: 0.4422\n",
      "Epoch 123/200, Train Loss: 0.7895, Val Loss: 0.4409\n",
      "Epoch 124/200, Train Loss: 0.7877, Val Loss: 0.4397\n",
      "Epoch 125/200, Train Loss: 0.7858, Val Loss: 0.4384\n",
      "Epoch 126/200, Train Loss: 0.7840, Val Loss: 0.4372\n",
      "Epoch 127/200, Train Loss: 0.7822, Val Loss: 0.4359\n",
      "Epoch 128/200, Train Loss: 0.7804, Val Loss: 0.4347\n",
      "Epoch 129/200, Train Loss: 0.7786, Val Loss: 0.4335\n",
      "Epoch 130/200, Train Loss: 0.7768, Val Loss: 0.4323\n",
      "Epoch 131/200, Train Loss: 0.7750, Val Loss: 0.4311\n",
      "Epoch 132/200, Train Loss: 0.7733, Val Loss: 0.4298\n",
      "Epoch 133/200, Train Loss: 0.7715, Val Loss: 0.4287\n",
      "Epoch 134/200, Train Loss: 0.7698, Val Loss: 0.4275\n",
      "Epoch 135/200, Train Loss: 0.7681, Val Loss: 0.4263\n",
      "Epoch 136/200, Train Loss: 0.7664, Val Loss: 0.4251\n",
      "Epoch 137/200, Train Loss: 0.7646, Val Loss: 0.4239\n",
      "Epoch 138/200, Train Loss: 0.7629, Val Loss: 0.4228\n",
      "Epoch 139/200, Train Loss: 0.7613, Val Loss: 0.4216\n",
      "Epoch 140/200, Train Loss: 0.7596, Val Loss: 0.4205\n",
      "Epoch 141/200, Train Loss: 0.7579, Val Loss: 0.4193\n",
      "Epoch 142/200, Train Loss: 0.7562, Val Loss: 0.4182\n",
      "Epoch 143/200, Train Loss: 0.7546, Val Loss: 0.4171\n",
      "Epoch 144/200, Train Loss: 0.7529, Val Loss: 0.4160\n",
      "Epoch 145/200, Train Loss: 0.7513, Val Loss: 0.4149\n",
      "Epoch 146/200, Train Loss: 0.7497, Val Loss: 0.4138\n",
      "Epoch 147/200, Train Loss: 0.7481, Val Loss: 0.4127\n",
      "Epoch 148/200, Train Loss: 0.7465, Val Loss: 0.4116\n",
      "Epoch 149/200, Train Loss: 0.7449, Val Loss: 0.4105\n",
      "Epoch 150/200, Train Loss: 0.7433, Val Loss: 0.4094\n",
      "Epoch 151/200, Train Loss: 0.7417, Val Loss: 0.4083\n",
      "Epoch 152/200, Train Loss: 0.7401, Val Loss: 0.4073\n",
      "Epoch 153/200, Train Loss: 0.7386, Val Loss: 0.4062\n",
      "Epoch 154/200, Train Loss: 0.7370, Val Loss: 0.4052\n",
      "Epoch 155/200, Train Loss: 0.7355, Val Loss: 0.4041\n",
      "Epoch 156/200, Train Loss: 0.7340, Val Loss: 0.4031\n",
      "Epoch 157/200, Train Loss: 0.7324, Val Loss: 0.4021\n",
      "Epoch 158/200, Train Loss: 0.7309, Val Loss: 0.4011\n",
      "Epoch 159/200, Train Loss: 0.7294, Val Loss: 0.4001\n",
      "Epoch 160/200, Train Loss: 0.7279, Val Loss: 0.3990\n",
      "Epoch 161/200, Train Loss: 0.7264, Val Loss: 0.3980\n",
      "Epoch 162/200, Train Loss: 0.7249, Val Loss: 0.3971\n",
      "Epoch 163/200, Train Loss: 0.7235, Val Loss: 0.3961\n",
      "Epoch 164/200, Train Loss: 0.7220, Val Loss: 0.3951\n",
      "Epoch 165/200, Train Loss: 0.7205, Val Loss: 0.3941\n",
      "Epoch 166/200, Train Loss: 0.7191, Val Loss: 0.3932\n",
      "Epoch 167/200, Train Loss: 0.7177, Val Loss: 0.3922\n",
      "Epoch 168/200, Train Loss: 0.7162, Val Loss: 0.3912\n",
      "Epoch 169/200, Train Loss: 0.7148, Val Loss: 0.3903\n",
      "Epoch 170/200, Train Loss: 0.7134, Val Loss: 0.3894\n",
      "Epoch 171/200, Train Loss: 0.7120, Val Loss: 0.3884\n",
      "Epoch 172/200, Train Loss: 0.7106, Val Loss: 0.3875\n",
      "Epoch 173/200, Train Loss: 0.7092, Val Loss: 0.3866\n",
      "Epoch 174/200, Train Loss: 0.7078, Val Loss: 0.3857\n",
      "Epoch 175/200, Train Loss: 0.7064, Val Loss: 0.3848\n",
      "Epoch 176/200, Train Loss: 0.7050, Val Loss: 0.3839\n",
      "Epoch 177/200, Train Loss: 0.7037, Val Loss: 0.3830\n",
      "Epoch 178/200, Train Loss: 0.7023, Val Loss: 0.3821\n",
      "Epoch 179/200, Train Loss: 0.7010, Val Loss: 0.3812\n",
      "Epoch 180/200, Train Loss: 0.6996, Val Loss: 0.3803\n",
      "Epoch 181/200, Train Loss: 0.6983, Val Loss: 0.3795\n",
      "Epoch 182/200, Train Loss: 0.6970, Val Loss: 0.3786\n",
      "Epoch 183/200, Train Loss: 0.6957, Val Loss: 0.3777\n",
      "Epoch 184/200, Train Loss: 0.6943, Val Loss: 0.3769\n",
      "Epoch 185/200, Train Loss: 0.6930, Val Loss: 0.3760\n",
      "Epoch 186/200, Train Loss: 0.6917, Val Loss: 0.3752\n",
      "Epoch 187/200, Train Loss: 0.6905, Val Loss: 0.3744\n",
      "Epoch 188/200, Train Loss: 0.6892, Val Loss: 0.3735\n",
      "Epoch 189/200, Train Loss: 0.6879, Val Loss: 0.3727\n",
      "Epoch 190/200, Train Loss: 0.6866, Val Loss: 0.3719\n",
      "Epoch 191/200, Train Loss: 0.6854, Val Loss: 0.3711\n",
      "Epoch 192/200, Train Loss: 0.6841, Val Loss: 0.3703\n",
      "Epoch 193/200, Train Loss: 0.6829, Val Loss: 0.3695\n",
      "Epoch 194/200, Train Loss: 0.6816, Val Loss: 0.3687\n",
      "Epoch 195/200, Train Loss: 0.6804, Val Loss: 0.3679\n",
      "Epoch 196/200, Train Loss: 0.6792, Val Loss: 0.3671\n",
      "Epoch 197/200, Train Loss: 0.6779, Val Loss: 0.3663\n",
      "Epoch 198/200, Train Loss: 0.6767, Val Loss: 0.3655\n",
      "Epoch 199/200, Train Loss: 0.6755, Val Loss: 0.3648\n",
      "Epoch 200/200, Train Loss: 0.6743, Val Loss: 0.3640\n"
     ]
    }
   ],
   "execution_count": 413
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
